{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "metallic-basics",
   "metadata": {},
   "source": [
    "# Random walk interpolate\n",
    "\n",
    "This notebook contains a small toy example, where TACTiS is used to predict the distribution of intermediate values of a random walk process, given values before and after them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-communications",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T00:40:55.811240Z",
     "iopub.status.busy": "2022-06-24T00:40:55.810708Z",
     "iopub.status.idle": "2022-06-24T00:40:55.813084Z",
     "shell.execute_reply": "2022-06-24T00:40:55.812632Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "import os\n",
    "import sys\n",
    "REPO_NAME = \"tactis\"\n",
    "def get_repo_basepath():\n",
    "    cd = os.path.abspath(os.curdir)\n",
    "    return cd[:cd.index(REPO_NAME) + len(REPO_NAME)]\n",
    "REPO_BASE_PATH = get_repo_basepath()\n",
    "sys.path.append(REPO_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-arnold",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T00:40:55.817143Z",
     "iopub.status.busy": "2022-06-24T00:40:55.816668Z",
     "iopub.status.idle": "2022-06-24T00:40:58.323954Z",
     "shell.execute_reply": "2022-06-24T00:40:58.323534Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tactis.model.tactis import TACTiS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-mining",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T00:40:58.327771Z",
     "iopub.status.busy": "2022-06-24T00:40:58.327362Z",
     "iopub.status.idle": "2022-06-24T00:40:58.329773Z",
     "shell.execute_reply": "2022-06-24T00:40:58.329426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose the device to run on. \n",
    "# For M1 Macs, device \"mps\" is not yet supported due to a bug in PyTorch \n",
    "# (as of 2022-07-26). See https://github.com/pytorch/pytorch/issues/81051 \n",
    "\n",
    "#device = torch.device(\"cuda\")\n",
    "#device = torch.device(\"mps\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-rehabilitation",
   "metadata": {},
   "source": [
    "## Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-onion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T00:40:58.333841Z",
     "iopub.status.busy": "2022-06-24T00:40:58.333439Z",
     "iopub.status.idle": "2022-06-24T00:40:58.336194Z",
     "shell.execute_reply": "2022-06-24T00:40:58.335789Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_random_data():\n",
    "    # Make a simple dataset just to test\n",
    "    np.random.seed(12345)\n",
    "    \n",
    "    n = 100000\n",
    "    p = 10\n",
    "\n",
    "    X = np.cumsum(np.random.randn(p, n), axis=1)\n",
    "\n",
    "    X_train = X[:, : n//2]\n",
    "    X_test = X[:, n//2 :]\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-relative",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-longer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T00:40:58.340566Z",
     "iopub.status.busy": "2022-06-24T00:40:58.340159Z",
     "iopub.status.idle": "2022-06-24T00:40:58.342674Z",
     "shell.execute_reply": "2022-06-24T00:40:58.342274Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_net():\n",
    "    net = TACTiS(\n",
    "        num_series=10,\n",
    "        series_embedding_dim=5,\n",
    "        input_encoder_layers=3,\n",
    "        input_encoding_normalization=True,\n",
    "        data_normalization=\"standardization\",\n",
    "        loss_normalization=\"series\",\n",
    "        positional_encoding={\n",
    "            \"dropout\": 0.0,\n",
    "        },\n",
    "        temporal_encoder={\n",
    "            \"attention_layers\": 3,\n",
    "            \"attention_heads\": 3,\n",
    "            \"attention_dim\": 16,\n",
    "            \"attention_feedforward_dim\": 16,\n",
    "            \"dropout\": 0.0,\n",
    "        },\n",
    "        copula_decoder={\n",
    "            \"min_u\": 0.01,\n",
    "            \"max_u\": 0.99,\n",
    "            \"attentional_copula\": {\n",
    "                \"attention_heads\": 3,\n",
    "                \"attention_layers\": 3,\n",
    "                \"attention_dim\": 16,\n",
    "                \"mlp_layers\": 3,\n",
    "                \"mlp_dim\": 16,\n",
    "                \"resolution\": 50,\n",
    "            },\n",
    "            \"dsf_marginal\": {\n",
    "                \"mlp_layers\": 2,\n",
    "                \"mlp_dim\": 8,\n",
    "                \"flow_layers\": 2,\n",
    "                \"flow_hid_dim\": 8,\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "    return net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-switch",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-judge",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T00:40:58.348316Z",
     "iopub.status.busy": "2022-06-24T00:40:58.347910Z",
     "iopub.status.idle": "2022-06-24T00:40:58.350389Z",
     "shell.execute_reply": "2022-06-24T00:40:58.350691Z"
    }
   },
   "outputs": [],
   "source": [
    "def step(net, optimizer, batch_size, data, hist_length_before, hist_length_after, pred_length):\n",
    "    max_idx = data.shape[1] - (hist_length_before + hist_length_after + pred_length)\n",
    "    \n",
    "    hist_values = []\n",
    "    pred_values = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, max_idx)\n",
    "        hist_values.append(np.concatenate([\n",
    "            data[:, idx:idx+hist_length_before],\n",
    "            data[:, idx+hist_length_before+pred_length:idx+hist_length_before+pred_length+hist_length_after]\n",
    "        ], axis=1))\n",
    "        pred_values.append(data[:, idx+hist_length_before:idx+hist_length_before+pred_length])\n",
    "    \n",
    "    # [batch, series, time steps]\n",
    "    hist_value = torch.Tensor(hist_values).to(device)\n",
    "    pred_value = torch.Tensor(pred_values).to(device)\n",
    "    hist_time = torch.cat([\n",
    "        torch.arange(0, hist_length_before, device=device),\n",
    "        torch.arange(hist_length_before+pred_length, hist_length_before+pred_length+hist_length_after, device=device),\n",
    "    ])[None, :].expand(batch_size, -1)\n",
    "    pred_time = torch.arange(hist_length_before, hist_length_before + pred_length, device=device)[None, :].expand(batch_size, -1)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = net.loss(hist_time, hist_value, pred_time, pred_value)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-center",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T00:40:58.354514Z",
     "iopub.status.busy": "2022-06-24T00:40:58.354075Z",
     "iopub.status.idle": "2022-06-24T00:41:00.546513Z",
     "shell.execute_reply": "2022-06-24T00:41:00.546869Z"
    }
   },
   "outputs": [],
   "source": [
    "net = create_net()\n",
    "data_train, data_test = generate_random_data()\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=1e-3, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-azerbaijan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T00:41:00.557375Z",
     "iopub.status.busy": "2022-06-24T00:41:00.556935Z",
     "iopub.status.idle": "2022-06-24T05:25:40.705445Z",
     "shell.execute_reply": "2022-06-24T05:25:40.705955Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_loss = []\n",
    "\n",
    "NUM_EPOCHS = 1000  # The model is very slow to train \n",
    "NUM_BATCHES = 100\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    running_sum = 0\n",
    "    for batch in range(NUM_BATCHES):\n",
    "        running_sum += step(net, optimizer, 256, data_train, 5, 5, 10)\n",
    "    avg_loss.append(running_sum / NUM_BATCHES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-shift",
   "metadata": {},
   "source": [
    "The loss function of TACTiS often contains multiple plateaus.\n",
    "For example, the first plateau can be the model correctly learning the global distribution, before learning the distribution conditioned on the history, and then learning the correlations between time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-still",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T05:25:40.719016Z",
     "iopub.status.busy": "2022-06-24T05:25:40.718564Z",
     "iopub.status.idle": "2022-06-24T05:25:40.862137Z",
     "shell.execute_reply": "2022-06-24T05:25:40.862426Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-laser",
   "metadata": {},
   "source": [
    "## Sampling from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-hollow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T05:25:40.868652Z",
     "iopub.status.busy": "2022-06-24T05:25:40.868206Z",
     "iopub.status.idle": "2022-06-24T05:25:40.869992Z",
     "shell.execute_reply": "2022-06-24T05:25:40.870317Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample(net, num_samples, data, hist_length_before, hist_length_after, pred_length):\n",
    "    max_idx = data.shape[1] - (hist_length_before + hist_length_after + pred_length)\n",
    "    \n",
    "    idx = np.random.randint(0, max_idx)\n",
    "    hist_value = torch.Tensor(np.concatenate([\n",
    "        data[:, idx:idx+hist_length_before],\n",
    "        data[:, idx+hist_length_before+pred_length:idx+hist_length_before+pred_length+hist_length_after]\n",
    "    ], axis=1)).to(device)\n",
    "    pred_value = torch.Tensor(data[:, idx+hist_length_before:idx+hist_length_before+pred_length]).to(device)\n",
    "    \n",
    "    # [batch, series, time steps]\n",
    "    hist_value = hist_value[None, :, :]\n",
    "    pred_value = pred_value[None, :, :]\n",
    "    hist_time = torch.cat([\n",
    "        torch.arange(0, hist_length_before, device=device),\n",
    "        torch.arange(hist_length_before+pred_length, hist_length_before+pred_length+hist_length_after, device=device),\n",
    "    ])[None, :]\n",
    "    pred_time = torch.arange(hist_length_before, hist_length_before + pred_length, device=device)[None, :]\n",
    "\n",
    "    samples = net.sample(num_samples, hist_time, hist_value, pred_time)   \n",
    "    return samples, torch.cat([hist_value, pred_value], axis=2), torch.cat([hist_time, pred_time], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-embassy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T05:25:40.873994Z",
     "iopub.status.busy": "2022-06-24T05:25:40.873546Z",
     "iopub.status.idle": "2022-06-24T05:25:41.946001Z",
     "shell.execute_reply": "2022-06-24T05:25:41.946315Z"
    }
   },
   "outputs": [],
   "source": [
    "samples, pred_value, timesteps = sample(net, 1000, data_test, 5, 5, 10)\n",
    "\n",
    "# Reorder for easy plotting\n",
    "permutation = [*range(5), *range(10, 20), *range(5, 10)]\n",
    "samples = samples[:, :, permutation, :]\n",
    "pred_value = pred_value[:, :, permutation]\n",
    "timesteps = timesteps[:, permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-knight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T05:25:41.954011Z",
     "iopub.status.busy": "2022-06-24T05:25:41.953549Z",
     "iopub.status.idle": "2022-06-24T05:25:41.954458Z",
     "shell.execute_reply": "2022-06-24T05:25:41.954752Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_single_series(samples, target, timesteps, index):\n",
    "    s_samples = samples[0, index, :, :].cpu().numpy()\n",
    "    s_timesteps = timesteps[0, :].cpu().numpy()\n",
    "    s_target = target[0, index, :].cpu().numpy()\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    for zorder, quant, color, label in [\n",
    "        [1, 0.05, (0.75,0.75,1), \"5%-95%\"],\n",
    "        [2, 0.10, (0.25,0.25,1), \"10%-90%\"],\n",
    "        [3, 0.25, (0,0,0.75), \"25%-75%\"],\n",
    "    ]:\n",
    "        plt.fill_between(\n",
    "            s_timesteps,\n",
    "            np.quantile(s_samples, quant, axis=1),\n",
    "            np.quantile(s_samples, 1 - quant, axis=1),\n",
    "            facecolor=color,\n",
    "            interpolate=True,\n",
    "            label=label,\n",
    "            zorder=zorder,\n",
    "        )\n",
    "    \n",
    "    plt.plot(\n",
    "        s_timesteps,\n",
    "        np.quantile(s_samples, 0.5, axis=1),\n",
    "        color=(0.5,0.5,0.5),\n",
    "        linewidth=3,\n",
    "        label=\"50%\",\n",
    "        zorder=4,\n",
    "    )\n",
    "    \n",
    "    plt.plot(s_timesteps, s_target, color=(0, 0, 0), linewidth=2, zorder=5, label=\"ground truth\")\n",
    "    \n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    order = [1, 2, 3, 4, 0]\n",
    "    plt.legend([handles[idx] for idx in order], [labels[idx] for idx in order])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-melissa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T05:25:41.958040Z",
     "iopub.status.busy": "2022-06-24T05:25:41.957643Z",
     "iopub.status.idle": "2022-06-24T05:25:42.703680Z",
     "shell.execute_reply": "2022-06-24T05:25:42.703340Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    plot_single_series(samples, pred_value, timesteps, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-concord",
   "metadata": {},
   "source": [
    "The variance of the random walk process for the interpolation scenario is more complicated, but can still be calculated analytically. It grows until the interpolation window midpoint before going back down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-subscriber",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T05:25:42.707857Z",
     "iopub.status.busy": "2022-06-24T05:25:42.707468Z",
     "iopub.status.idle": "2022-06-24T05:25:42.805391Z",
     "shell.execute_reply": "2022-06-24T05:25:42.805697Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(samples[0, :, :, :].var(dim=2).cpu().transpose(0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-nevada",
   "metadata": {},
   "source": [
    "The correlations should increase as we go to the middle time steps, especially for close time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-productivity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T05:25:42.809987Z",
     "iopub.status.busy": "2022-06-24T05:25:42.809587Z",
     "iopub.status.idle": "2022-06-24T05:25:42.896143Z",
     "shell.execute_reply": "2022-06-24T05:25:42.896443Z"
    }
   },
   "outputs": [],
   "source": [
    "corrcoef = 0\n",
    "for b in range(samples.shape[0]):\n",
    "    for v in range(samples.shape[1]):\n",
    "        spl = samples[b,v,5:15,:].cpu().numpy()\n",
    "        corrcoef = corrcoef + np.corrcoef(spl)\n",
    "corrcoef /= (samples.shape[0] * samples.shape[1])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "svm = sns.heatmap(corrcoef, robust=True, center=0, xticklabels=False, yticklabels=False)\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
